---
title: "hw1"
author: "Bedros, Haig; Dela Cruz, Sandra; Hugh, Tiffany; Li, Yanyi"
date: "2025-02-16"
output: html_document
---

```{r warning=FALSE}
library(tidyverse)
library(knitr)
library(DataExplorer)
library(readr)
```

### Section 1: DATA EXPLORATION

```{r}
#upload training data set
moneyball_training_data <- read_csv("https://raw.githubusercontent.com/tiffhugh/DATA-621/refs/heads/main/moneyball-training-data.csv", show_col_types = FALSE)
```

```{r}
# preview of training data
head(moneyball_training_data)
```

```{r}
# check dimensions of the data set
dim(moneyball_training_data)
```

For our moneyball training data set we have 2276 observations and 17 columns. For easy exploration, let's describe the group of variables first, and exclude `INDEX` since we will not need it . Please see as follows:

-   `TARGET_WINS` - our dependent variable

-   `TEAM_BATTING` - refers to a team's offensive ability when hitting the ball

-   `TEAM_BASERUN` - determines how efficiently a team navigates the bases after hitting the ball

-   `TEAM_FIELDING` - is the defensive skill of catching and throwing the ball to record outs

-   `TEAM_PITCHING` - represents the ability of a team's pitchers to throw strikes and prevent the opposing team from hitting the ball effectively

```{r}
# remove index variable in our dataset
moneyball_training_data = moneyball_training_data[,-1]
```

Below is the summary of each of our individual variables, this includes the minimum, median, mean, and maximum values. With this we can easily spot that we have a minimum of zero on most of our variables, we can also see that we have a lot of missing values for some of our variables, are this going to be a concern for us? Let's find out.

```{r}
# let's get a summary of our data
summary(moneyball_training_data)
```

To help us further with our exploration, let's have quick overview of our histogram and q-q plot to check for the normality of distribution of our data and to easily spot outliers that might suggest to fix our missing values or transform our variables later.

```{r}
# let's plot a histogram using DataExplorer library
plot_histogram(moneyball_training_data)
```

```{r warning=FALSE}
# let's plot a qq plot
plot_qq(moneyball_training_data)
```

With an overview of both graphs, we can see that only some of the variables are normally distributed, let's say the variables `TEAM_BATTING_2B`, `TEAM_BATTING_HBP`, and `TEAM_FIELDING_DP`, the others are skewed to the right with reference to our histogram, either having a curve or a heavy tail with reference to our q-q plot.

### Section 2: DATA PREPARATION

```{r}
# Find the total number of missing values in the dataset
sum(is.na(moneyball_training_data))
```

The Money Ball training dataset has 3,478 missing values. Since the distributions are skewed, we will replace the missing values with the median.

```{r}
# Replace missing values with median for numerical variables
moneyball_training_data <- moneyball_training_data %>%
  mutate(across(where(is.numeric), ~replace_na(., median(., na.rm = TRUE))))
```

We categorized the teams based on the number of base hits by batters (1B, 2B, 3B, HR), where 1 represents the lowest and 4 represents the highest.

```{r}
# Create a new column for binning TEAM_BATTING_H (Total Hits) into quartiles
moneyball_training_data <- moneyball_training_data %>%
  mutate(TEAM_BATTING_H_BIN = ntile(TEAM_BATTING_H, 4))
```

```{r}
# Check the number of teams in each bin for TEAM_BATTING_H (Total Hits)
table(moneyball_training_data$TEAM_BATTING_H_BIN)
```

There are 569 records in each bin, distributed very evenly.

We will apply the previous steps to a different column, specifically the number of wins.

```{r}
# Create a new column for binning TARGET_WINS (Number of wins) into quartiles
moneyball_training_data <- moneyball_training_data %>%
  mutate(TARGET_WINS_BIN = ntile(TARGET_WINS, 4))
```

```{r}
# Check the number of teams in each bin for TEAM_BATTING_H (Total Hits)
table(moneyball_training_data$TARGET_WINS_BIN)
```

Surprisingly, we can see that there are also 569 records in each bin.


### Section 3: BUILD MODELS

Below are three different multiple linear regression models developed to predict the number of wins.

#### Model 1: Full Model

We start by including all key variables that are expected to influence wins.

```{r model1, echo=TRUE}
model1 <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_BATTING_HBP + TEAM_BATTING_SO + TEAM_BASERUN_SB + TEAM_BASERUN_CS + TEAM_FIELDING_E + TEAM_FIELDING_DP +
TEAM_PITCHING_BB + TEAM_PITCHING_H + TEAM_PITCHING_HR + TEAM_PITCHING_SO, data = moneyball_training_data)
summary(model1)
```

### Key Points:

- **Overall Fit:**  
  - Adjusted R-squared is 0.311, indicating that about 31% of the variation in wins is explained by the model.  
  - The overall model is statistically significant (F p < 2.2e-16).

- **Significant Predictors:**  
  - **Positive Effects:** TEAM_BATTING_H, TEAM_BATTING_3B, and TEAM_BASERUN_SB strongly predict higher wins.
  - **Negative Effects:** TEAM_FIELDING_E and TEAM_FIELDING_DP are significant, suggesting that fewer errors and double plays boost wins. Additionally, TEAM_BATTING_SO negatively impacts wins, while TEAM_PITCHING_SO has a positive effect.

### That means:
- The model explains about 31% of the variation in wins.
- More total hits, triples, and stolen bases are linked to more wins.
- The coefficients mostly follow our expectations (e.g., a positive impact for home runs).
- Fewer fielding errors and double plays are important for winning.
- Batting strikeouts hurt the team, while more pitching strikeouts help.
- Some variables (like doubles, home runs, hit-by-pitch, and caught stealing) are less important or not statistically significant.


#### Model 2: Reduced Model

Next, we simplify the model by removing variables that are not statistically significant or are redundant.

```{r model2, echo=TRUE}
model2 <- lm(TARGET_WINS ~ TEAM_BATTING_HR + TEAM_BASERUN_SB +
              TEAM_FIELDING_E + TEAM_PITCHING_SO + TEAM_PITCHING_H,
              data = moneyball_training_data)
summary(model2)
```
### Key Points:

- **Overall Fit:**  
  - Adjusted R-squared is 0.1039, meaning about 10.4% of the variation in wins is explained by the model.  
  - The overall model is statistically significant (F p < 2.2e-16).

- **Significant Predictors:**  
  - **Positive Effects:** TEAM_BATTING_HR, TEAM_BASERUN_SB, and TEAM_PITCHING_H are significantly linked to higher wins.  
  - **Negative Effects:** TEAM_FIELDING_E and TEAM_PITCHING_SO show significant negative effects on wins.

### That means:
- The reduced model explains about 10% of the variation in wins.
- More home runs and stolen bases are associated with more wins.
- Better fielding (fewer errors) is important for winning.
- The effects of pitching variables (more hits allowed predict higher wins while more strikeouts predict lower wins) are significant.


#### Model 3: Model with Transformations/Interactions

Finally, we experiment with transformations and interactions. Here, we create a new variable, *HR_Efficiency* (the ratio of home runs to total hits), and apply a log transformation to reduce skewness in stolen bases. We also include an interaction between home runs and pitching strikeouts.

```{r model3, echo=TRUE}
moneyball_training_data$HR_Efficiency <- moneyball_training_data$TEAM_BATTING_HR / moneyball_training_data$TEAM_BATTING_H
model3 <- lm(TARGET_WINS ~ log(TEAM_BASERUN_SB + 1) + TEAM_FIELDING_E +
              HR_Efficiency + TEAM_PITCHING_SO + TEAM_BATTING_HR * TEAM_PITCHING_SO,
              data = moneyball_training_data)
summary(model3)
```


### Section 4: SELECT MODELS

