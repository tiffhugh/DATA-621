---
title: "hw1_baseball prediction"
author: "Bedros, Haig; Dela Cruz, Sandra; Hugh, Tiffany; Li, Yanyi"
date: "2025-02-26"
output: html_document
---
<style type="text/css">

h1.title {
  font-size: 26px;
  color: Black;
  text-align: center;
}
h4.author { 
  font-size: 18px;
  color: Black;
  text-align: center;
}
h4.date {
  font-size: 12px;
  color: Black;
  text-align: center;
}
</style>

```{r setup1, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = TRUE,
	warning = TRUE)
#install.packages(c("tidyverse", "knitr", "readr","DataExplorer","ggplot2", "reshape2"))
library(tidyverse)
library(knitr)
library(DataExplorer)
library(readr)
library(ggplot2)
library(reshape2)

#training data 
moneyball_training_data <- read_csv("https://raw.githubusercontent.com/tiffhugh/DATA-621/refs/heads/main/moneyball-training-data.csv", show_col_types = FALSE)
View(moneyball_training_data)
#evaluation data 
moneyball_evaluation_data <- read_csv("https://raw.githubusercontent.com/tiffhugh/DATA-621/refs/heads/main/moneyball-evaluation-data.csv", show_col_types = FALSE)
View(moneyball_evaluation_data)
```

<h3>**Section 1: DATA EXPLORATION**</h3>
For our moneyball training data set we have 2276 observations and 17 columns. For easy exploration, let's describe the group of variables first, and exclude `INDEX` since we will not need it . Please see as follows:

-   `TARGET_WINS` - our dependent variable

-   `TEAM_BATTING` - refers to a team's offensive ability when hitting the ball

-   `TEAM_BASERUN` - determines how efficiently a team navigates the bases after hitting the ball

-   `TEAM_FIELDING` - is the defensive skill of catching and throwing the ball to record outs

-   `TEAM_PITCHING` - represents the ability of a team's pitchers to throw strikes and prevent the opposing team from hitting the ball effectively

Below is the summary of each of our individual variables, this includes the minimum, median, mean, and maximum values. With this we can easily spot that we have a minimum of zero on most of our variables, we can also see that we have a lot of missing values for some of our variables, are this going to be a concern for us? Let's find out.

```{r setup2, include=TRUE}
knitr::opts_chunk$set(echo = FALSE,
	message = TRUE,
	warning = TRUE)
summary(moneyball_training_data)
```

The average number of team wins is approximately 81, with a range from 0 to 146, suggesting a wide variance in the teams' success. The team typically has 1,469 hits per season, with notable variability in extra-base hits such as doubles (mean = 241) and triples (mean = 55). Home runs range from 0 to 264, while walks and strikeouts average around 502 and 736, respectively. Pitching statistics reveal that teams allow an average of 1,779 hits and 105 home runs, while fielding metrics indicate an average of 246 errors per season. There is also the presence of missing values which could be attributed to many things that can occur during a game.

To help us further with our exploration, let's have quick overview of our histogram and q-q plot to check for the normality of distribution of our data and to easily spot outliers that might suggest to fix our missing values or transform our variables later.

<h4>**Histogram**</h4>
![](histogram.png)

<h4>**Q-Q Plots**</h4>
![](qqp1.png)
![](qqp2.png)

With an overview of both graphs, we can see that only some of the variables are normally distributed, let's say the variables `TEAM_BATTING_2B`, `TEAM_BATTING_HBP`, and `TEAM_FIELDING_DP`, the others are skewed to the right with reference to our histogram, either having a curve or a heavy tail with reference to our q-q plot.

Our goal is to predict the team's target wins, so analyzing correlations will help identify which variables have the strongest impact on winning outcomes.
<h4>**Correlation Matrix**</h4>
![](corr.png)

The strongest positive correlations with wins are seen in TEAM_BATTING_H (+0.35), TEAM_BATTING_BB (+0.30), and TEAM_BATTING_2B (+0.26), indicating that hits, walks, and doubles contribute significantly to scoring runs. Conversely, TEAM_FIELDING_E (-0.17) and TEAM_PITCHING_H (-0.08) show negative correlations, suggesting that poor defense and allowing more hits can reduce wins. Weak correlations, such as TEAM_BATTING_SO (-0.03) and TEAM_FIELDING_DP (-0.03), indicate that strikeouts and double plays have little impact. For model building, TEAM_BATTING_H, TEAM_BATTING_BB, TEAM_BATTING_2B, TEAM_BATTING_HR, and TEAM_PITCHING_HR should be prioritized as key predictive features.

<h3>**Section 2: DATA PREPARATION**</h3>
### Section 2: DATA PREPARATION

```{r echo=FALSE}
# Find the total number of missing values in the dataset
cat("Find the total number of missing values in the dataset: ", sum(is.na(moneyball_training_data)), "\n")
```

From our data exploration, we found that our moneyball training dataset has a total of 3,478 missing values. We replaced these missing values with their respective median values, since the distributions are skewed. Using the median is beneficial because it is less sensitive to extremes or outliers, helping maintain the natural spread and variability of the data. This approach avoids overestimating the performance of the players. In reality, it represents the typical player’s performance, whereas using mean might shift the data on levels that do not accurately reflect the majority of players.

```{r}
# Replace missing values with median for numerical variables
cat("Replace missing values with median for numerical variables: \n")
moneyball_training_data <- moneyball_training_data %>%
  mutate(across(where(is.numeric), ~replace_na(., median(., na.rm = TRUE))))

cor_matrix <- cor(moneyball_training_data, use = "complete.obs")
cor_matrix["TARGET_WINS", ]

cor_matrix <- cor(moneyball_training_data, use = "complete.obs")
cor_melted <- melt(cor_matrix)

ggplot(cor_melted, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(title = "Correlation Matrix", fill = "Correlation")
```


To better understand the data, we categorized the teams into four quartiles based on their total number of wins. Quartile 1 represents the lowest number of wins, while Quartile 4 represents the highest.
```{r echo=FALSE}
# Create a new column for binning TARGET_WINS (Number of wins) into quartiles
moneyball_training_data <- moneyball_training_data %>%
  mutate(TARGET_WINS_BIN = ntile(TARGET_WINS, 4))

cat("Here's an overiew of the new column created:\n")
head(moneyball_training_data[, c("TARGET_WINS", "TARGET_WINS_BIN")])
```

This approach makes it easier to analyze each team’s performance and determine which tier they belong to. Interestingly, we can see that there are also 569 records in each bin.

```{r echo=FALSE}
# Check the number of teams in each bin for TARGET_WINS (Number of wins)
cat("Check the number of teams in each bin for TARGET_WINS (Number of wins): \n")
table(moneyball_training_data$TARGET_WINS_BIN)
```

In order to assess how efficiently a player turns their at-bat (which represents a batter's turn to hit, including results such as a hit, walk, strikeout, or foul ball) into home runs, we introduced a new variable called HR_efficiency. This variable measures the ratio of home runs to total base hits for batters, calculated by dividing the number of home runs by the total number of base hits. By interpreting this metric, the higher the value, the more efficient the player is at hitting home runs. HR_efficiency can be an important indicator of a player's power-hitting ability.

```{r echo=FALSE}
moneyball_training_data$HR_Efficiency <- moneyball_training_data$TEAM_BATTING_HR / moneyball_training_data$TEAM_BATTING_H

cat("Here's an overiew of the new column created:\n")
head(moneyball_training_data[, c("TEAM_BATTING_HR", "TEAM_BATTING_H", "HR_Efficiency")])
```

<h3>**Section 3: BUILD MODELS**</h3>

Below are three different multiple linear regression models developed to predict the number of wins.

<h4>**Model 1: Full Model**</h4>

We start by including all key variables that are expected to influence wins.
```{r setup3, include=TRUE}
knitr::opts_chunk$set(echo = FALSE,
	message = TRUE,
	warning = TRUE)
model1 <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_BATTING_HBP + TEAM_BATTING_SO + TEAM_BASERUN_SB + TEAM_BASERUN_CS + TEAM_FIELDING_E + TEAM_FIELDING_DP +
TEAM_PITCHING_BB + TEAM_PITCHING_H + TEAM_PITCHING_HR + TEAM_PITCHING_SO, data = moneyball_training_data)
summary(model1)
```
<h4>**Model 1 Plots**</h4>
![](mod1vs.png)
![](mod1qq.png)
![](mod1scale.png)
![](mod1rl.png)
<h4>**Key Points**</h4>

_Overall Fit_

  - Adjusted R-squared is 0.311, indicating that about 31% of the variation in wins is explained by the model.  
  - The overall model is statistically significant (F p < 2.2e-16).

_Significant Predictors_

  - Positive Effects: TEAM_BATTING_H, TEAM_BATTING_3B, and TEAM_BASERUN_SB strongly predict higher wins.
  - Negative Effects: TEAM_FIELDING_E and TEAM_FIELDING_DP are significant, suggesting that fewer errors and double plays boost wins. 
  , TEAM_BATTING_SO negatively impacts wins, while TEAM_PITCHING_SO has a positive effect.

_Interpretation_

  - The model explains about 31% of the variation in wins.
  - More total hits, triples, and stolen bases are linked to more wins.
  - The coefficients mostly follow our expectations (e.g., a positive impact for home runs).
  - Fewer fielding errors and double plays are important for winning.
  - Batting strikeouts hurt the team, while more pitching strikeouts help.
  - Some variables (like doubles, home runs, hit-by-pitch, and caught stealing) are less important or not statistically significant.

<h4>**Model 2: Reduced Model**</h4>

Next, we simplify the model by removing variables that are not statistically significant or are redundant.
```{r setup4, include=TRUE}
knitr::opts_chunk$set(echo = FALSE,
	message = TRUE,
	warning = TRUE)
model2 <- lm(TARGET_WINS ~ TEAM_BATTING_HR + TEAM_BASERUN_SB +
              TEAM_FIELDING_E + TEAM_PITCHING_SO + TEAM_PITCHING_H,
              data = moneyball_training_data)
summary(model2)
```
<h4>**Model 2 Plots**</h4>
![](mod2vs.png)
![](mod2qq.png)
![](mod2sl.png)
![](mod2sl.png)
![](mod2rl.png)

<h4>**Key Points**</h4>

_Overall Fit_

  - Adjusted R-squared is 0.1039, meaning about 10.4% of the variation in wins is explained by the model.  
  - The overall model is statistically significant (F p < 2.2e-16).

_Significant Predictors_

  - Positive Effects: TEAM_BATTING_HR, TEAM_BASERUN_SB, and TEAM_PITCHING_H are significantly linked to higher wins.  
  - Negative Effects:TEAM_FIELDING_E and TEAM_PITCHING_SO show significant negative effects on wins.

_Interpretation_

  - The reduced model explains about 10% of the variation in wins.
  - More home runs and stolen bases are associated with more wins.
  - Better fielding (fewer errors) is important for winning.
  - The effects of pitching variables (more hits allowed predict higher wins while more strikeouts predict lower wins) are significant.
  
<h4>**Model 3: Model with Transformations/Interactions**</h4>

Finally, we experiment with transformations and interactions. Here, we create a new variable, HR_Efficiency (the ratio of home runs to total hits), and apply a log transformation to reduce skewness in stolen bases. We also include an interaction between home runs and pitching strikeouts.

```{r setup5, include=TRUE}
knitr::opts_chunk$set(echo = FALSE,
	message = TRUE,
	warning = TRUE)
model3 <- lm(TARGET_WINS ~ log(TEAM_BASERUN_SB + 1) + TEAM_FIELDING_E +
              HR_Efficiency + TEAM_PITCHING_SO + TEAM_BATTING_HR * TEAM_PITCHING_SO,
              data = moneyball_training_data)
summary(model3)
```
<h4>**Model 3 Plots**</h4>
![](mod3rf.png)
![](qqp3.png)
![](mod3sl.png)
![](mod3rl.png)
<h4>**Key Points**</h4>

_Overall Fit_

  - Adjusted R-squared is 0.2573, meaning about 25.7% of the variation in wins is explained by the model.
  - The overall model is statistically significant (F p < 2.2e-16).
  
_Significant Predictors_

 -  Positive Effects: log(TEAM_BASERUN_SB + 1), TEAM_BATTING_HR are significantly linked to higher wins.
 -  Negative Effects: TEAM_FIELDING_E, HR_Efficiency, and TEAM_PITCHING_SO show significant negative effects on wins.
 -  Interaction Effect: TEAM_BATTING_HR * TEAM_PITCHING_SO has a negative impact, meaning that as both increase, their combined effect on wins diminishes.

_Interpretation_

  - The model explains about 25.7% of the variation in wins.
  - More home runs and stolen bases are associated with more wins.
  - Better fielding (fewer errors) is crucial for winning.
  - Higher strikeouts by pitchers are unexpectedly linked to fewer wins, possibly due to other underlying factors like walks or home runs allowed
  - HR Efficiency’s negative effect suggests that simply hitting home runs efficiently doesn’t always translate to more wins.

<h3>**Section 4: SELECT MODELS**</h3>

To select the best multiple linear regression model, we will use the Moneyball evaluation dataset to assess their performances. First, we will apply all the transformations we implemented on the training dataset, and then we will use the three models to make predictions.

Since we cannot compare predictions to the actual number of wins for the teams in the evaluation data set, we can instead evaluate the spread of their distributions. If a model produces extreme values, it may not be a reliable model.

<h4>**Boxplot**</h4>
![](boxplot.png)
Both models 2 and 3 have many outliers, indicating they may not serve as good regression models. We can then compare the Adjusted R-squared values for all three models.

```{r setup6, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
	message = TRUE,
	warning = TRUE)
	# Ensure the evaluation dataset has the same transformations as training data
moneyball_evaluation_data <- moneyball_evaluation_data %>%
  mutate(HR_Efficiency = ifelse(TEAM_BATTING_H == 0 | is.na(TEAM_BATTING_H), 0, TEAM_BATTING_HR / TEAM_BATTING_H),
         log_TEAM_BASERUN_SB = log(ifelse(is.na(TEAM_BASERUN_SB), 0, TEAM_BASERUN_SB) + 1))

# Predict using the three models
pred_model1 <- predict(model1, newdata = moneyball_evaluation_data)
pred_model2 <- predict(model2, newdata = moneyball_evaluation_data)
pred_model3 <- predict(model3, newdata = moneyball_evaluation_data)
	
```	
```{r setup7, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
	message = TRUE,
	warning = TRUE)	
summary(model1)$adj.r.squared
summary(model2)$adj.r.squared
summary(model3)$adj.r.squared	
```
A higher Adjusted R-squared value indicates a better fit for the model. In this case, model 1 has a significantly higher Adjusted R-squared value compared to the other two models. Additionally, we can compare the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) for all three models.

```{r setup8, include=TRUE}
knitr::opts_chunk$set(echo = FALSE,
	message = TRUE,
	warning = TRUE)	
# Compare Akaike Information Criterion (AIC)
AIC(model1, model2, model3)
BIC(model1, model2, model3)
```
Both the AIC and BIC suggest that Model 1 is the superior choice, as it has lower AIC and BIC values. This indicates a better balance between fit and complexity. Overall, Model 1 is the best multiple regression model among the three options.


<h3>**Appendix**</h3>
```{r setup9, echo=TRUE, eval=FALSE}

knitr::opts_chunk$set(echo = FALSE,
	message = TRUE,
	warning = TRUE)	

library(tidyverse)
library(knitr)
library(DataExplorer)
library(readr)

### Section 1: DATA EXPLORATION

#upload training data set
moneyball_training_data <- read_csv("https://raw.githubusercontent.com/tiffhugh/DATA-621/refs/heads/main/moneyball-training-data.csv", show_col_types = FALSE)

# preview of training data
head(moneyball_training_data)

# check dimensions of the data set
dim(moneyball_training_data)

#upload evaluation data set
moneyball_evaluation_data <- read_csv("https://raw.githubusercontent.com/tiffhugh/DATA-621/refs/heads/main/moneyball-evaluation-data.csv", show_col_types = FALSE)

#For our moneyball training data set we have 2276 observations and 17 columns. For easy exploration, let's describe the group of variables first, and exclude `INDEX` since we will not need it . Please see as follows:

#-   `TARGET_WINS` - our dependent variable

#-   `TEAM_BATTING` - refers to a team's offensive ability when hitting the ball

#-   `TEAM_BASERUN` - determines how efficiently a team navigates the bases after hitting the ball

#-   `TEAM_FIELDING` - is the defensive skill of catching and throwing the ball to record outs

#-   `TEAM_PITCHING` - represents the ability of a team's pitchers to throw strikes and prevent the opposing team from hitting the ball effectively

# remove index variable in our dataset
moneyball_training_data = moneyball_training_data[,-1]

#Below is the summary of each of our individual variables, this includes the minimum, median, mean, and maximum values. With this we can easily spot that we have a minimum of zero on most of our variables, we can also see that we have a lot of missing values for some of our variables, are this going to be a concern for us? Let's find out.

# let's get a summary of our data
summary(moneyball_training_data)

#To help us further with our exploration, let's have quick overview of our histogram and q-q plot to check for the normality of distribution of our data and to easily spot outliers that might suggest to fix our missing values or transform our variables later.

# let's plot a histogram using DataExplorer library
plot_histogram(moneyball_training_data)

# let's plot a qq plot
plot_qq(moneyball_training_data)

#With an overview of both graphs, we can see that only some of the variables are normally distributed, let's say the variables `TEAM_BATTING_2B`, `TEAM_BATTING_HBP`, and `TEAM_FIELDING_DP`, the others are skewed to the right with reference to our histogram, either having a curve or a heavy tail with reference to our q-q plot.

### Section 2: DATA PREPARATION

#### Fixing missing values with median value

# Find the total number of missing values in the dataset
sum(is.na(moneyball_training_data))

#The Money ball training dataset has a total of 3,478 missing values. We will replace the missing values with the median since the distributions are skewed.

# Replace missing values with median for numerical variables
moneyball_training_data <- moneyball_training_data %>%
  mutate(across(where(is.numeric), ~replace_na(., median(., na.rm = TRUE))))
cor_matrix <- cor(moneyball_training_data, use = "complete.obs")
cor_matrix["TARGET_WINS", ]

#install.packages("ggplot2")
#install.packages("reshape2")
#library(ggplot2)
#library(reshape2)

cor_matrix <- cor(moneyball_training_data, use = "complete.obs")
cor_melted <- melt(cor_matrix)

ggplot(cor_melted, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(title = "Correlation Matrix", fill = "Correlation")

#### Transforming data by putting it into buckets

#We categorized the teams into four quartiles based on their total number of wins. Quartile 1 represents the lowest number of wins, while Quartile 4 represents the highest. This approach makes it easier to analyze each team's performance and determine which tier they belong to.

# Create a new column for binning TARGET_WINS (Number of wins) into quartiles
moneyball_training_data <- moneyball_training_data %>%
  mutate(TARGET_WINS_BIN = ntile(TARGET_WINS, 4))

# Check the number of teams in each bin for TARGET_WINS (Number of wins)
table(moneyball_training_data$TARGET_WINS_BIN)

#Surprisingly, we can see that there are also 569 records in each bin.

#### Adding new variable HR_Efficiency

#Next, we will introduce a new variable called HR_efficiency. This variable is calculated by dividing the number of home runs by batters by the total number of base hits by batters. This calculation provides us with the ratio of home runs to total hits.

moneyball_training_data$HR_Efficiency <- moneyball_training_data$TEAM_BATTING_HR / moneyball_training_data$TEAM_BATTING_H

### Section 3: BUILD MODELS

#Below are three different multiple linear regression models developed to predict the number of wins.

#### Model 1: Full Model

#We start by including all key variables that are expected to influence wins.

model1 <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_BATTING_HBP + TEAM_BATTING_SO + TEAM_BASERUN_SB + TEAM_BASERUN_CS + TEAM_FIELDING_E + TEAM_FIELDING_DP +
TEAM_PITCHING_BB + TEAM_PITCHING_H + TEAM_PITCHING_HR + TEAM_PITCHING_SO, data = moneyball_training_data)
summary(model1)

plot(model1)

### Key Points:

# **Overall Fit:**  
 # - Adjusted R-squared is 0.311, indicating that about 31% of the variation in wins is explained by the model.  
  #- The overall model is statistically significant (F p < 2.2e-16).

# **Significant Predictors:**  
#  - **Positive Effects:** TEAM_BATTING_H, TEAM_BATTING_3B, and TEAM_BASERUN_SB strongly predict higher wins.
 # - **Negative Effects:** TEAM_FIELDING_E and TEAM_FIELDING_DP are significant, suggesting that fewer errors and double plays boost wins. Additionally, TEAM_BATTING_SO negatively impacts wins, while TEAM_PITCHING_SO has a positive effect.

### That means:
## More total hits, triples, and stolen bases are linked to more wins.
#
#The coefficients mostly follow our expectations (e.g., a positive impact for home runs).
#Fewer fielding errors and double plays are important for winning.
#Batting strikeouts hurt the team, while more pitching strikeouts help.
# Some variables (like doubles, home runs, hit-by-pitch, and caught stealing) are less important or not statistically significant.

#### Model 2: Reduced Model

#Next, we simplify the model by removing variables that are not statistically significant or are redundant.

model2 <- lm(TARGET_WINS ~ TEAM_BATTING_HR + TEAM_BASERUN_SB +
              TEAM_FIELDING_E + TEAM_PITCHING_SO + TEAM_PITCHING_H,
              data = moneyball_training_data)
summary(model2)

plot(model2)

### Key Points:

# **Overall Fit:**  
 # - Adjusted R-squared is 0.1039, meaning about 10.4% of the variation in wins is explained by the model.  
 # - The overall model is statistically significant (F p < 2.2e-16).

# **Significant Predictors:**  
 # - **Positive Effects:** TEAM_BATTING_HR, TEAM_BASERUN_SB, and TEAM_PITCHING_H are significantly linked to higher wins.  
  #- **Negative Effects:** TEAM_FIELDING_E and TEAM_PITCHING_SO show significant negative effects on wins.

### That means:
#- The reduced model explains about 10% of the variation in wins.
# More home runs and stolen bases are associated with more wins.
# Better fielding (fewer errors) is important for winning.
# The effects of pitching variables (more hits allowed predict higher wins while more strikeouts predict lower wins) are significant.

#### Model 3: Model with Transformations/Interactions
#Finally, we experiment with transformations and interactions. Here, we create a new variable, *HR_Efficiency* (the ratio of home runs to total hits), and apply a log transformation to reduce skewness in stolen bases. We also include an interaction between home runs and pitching strikeouts.

model3 <- lm(TARGET_WINS ~ log(TEAM_BASERUN_SB + 1) + TEAM_FIELDING_E +
              HR_Efficiency + TEAM_PITCHING_SO + TEAM_BATTING_HR * TEAM_PITCHING_SO,
              data = moneyball_training_data)
summary(model3)

plot(model3)

### Section 4: SELECT MODELS

#To select the best multiple linear regression model, we will use the Moneyball evaluation dataset to assess their performances. First, we will apply all the transformations we implemented on the training dataset, and then we will use the three models to make predictions.

# Ensure the evaluation dataset has the same transformations as training data
moneyball_evaluation_data <- moneyball_evaluation_data %>%
  mutate(HR_Efficiency = ifelse(TEAM_BATTING_H == 0 | is.na(TEAM_BATTING_H), 0, TEAM_BATTING_HR / TEAM_BATTING_H),
         log_TEAM_BASERUN_SB = log(ifelse(is.na(TEAM_BASERUN_SB), 0, TEAM_BASERUN_SB) + 1))

# Predict using the three models
pred_model1 <- predict(model1, newdata = moneyball_evaluation_data)
pred_model2 <- predict(model2, newdata = moneyball_evaluation_data)
pred_model3 <- predict(model3, newdata = moneyball_evaluation_data)

#Since we cannot compare predictions to the actual number of wins for the teams in the evaluation data set, we can instead evaluate the spread of their distributions. If a model produces extreme values, it may not be a reliable model.

boxplot(pred_model1, pred_model2, pred_model3, 
        names = c("Model 1", "Model 2", "Model 3"),
        main = "Comparison of Predictions", col = c("blue3", "red3", "green4"))

#Both models 2 and 3 have many outliers, indicating they may not serve as good regression models. We can then compare the Adjusted R-squared values for all three models.

  # Adjusted R-squared for all three models
summary(model1)$adj.r.squared
summary(model2)$adj.r.squared
summary(model3)$adj.r.squared

#A higher Adjusted R-squared value indicates a better fit for the model. In this case, model 1 has a significantly higher Adjusted R-squared value compared to the other two models. Additionally, we can compare the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) for all three models.

# Compare Akaike Information Criterion (AIC)
AIC(model1, model2, model3)

# Compare Bayesian Information Criterion (BIC)
BIC(model1, model2, model3)

#Both the AIC and BIC suggest that Model 1 is the superior choice, as it has lower AIC and BIC values. This indicates a better balance between fit and complexity. Overall, Model 1 is the best multiple regression model among the three options.
```
	
